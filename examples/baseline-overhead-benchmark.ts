// examples/simple-loops-benchmark.ts
// Simple loops per second calculation based on observed overhead
import {performance} from 'perf_hooks'
import {threader, thread} from '../src/index'

async function calculateLoopsPerSecond(): Promise<void> {
  console.log('üîÑ THREADER LOOPS PER SECOND ANALYSIS')
  console.log('Based on observed overhead measurements')
  console.log('=' * 50)

  // Use the data we already know from previous benchmarks
  const knownOverhead = {
    operations: 10,
    threaderTime: 87.9, // ms
    nativeTime: 0.0001, // estimated
    setupTime: 88.6 // ms for 100 processors
  }

  console.log('\nüìä OBSERVED PERFORMANCE DATA:')
  console.log(`‚úÖ 10 operations completed in ${knownOverhead.threaderTime}ms`)
  console.log(`‚úÖ 100 processors created in ${knownOverhead.setupTime}ms`)
  console.log(
    `‚úÖ Average setup time: ${(knownOverhead.setupTime / 100).toFixed(
      2
    )}ms per processor`
  )

  // Calculate current throughput
  const currentOpsPerSec =
    (knownOverhead.operations / knownOverhead.threaderTime) * 1000
  const currentLatencyMs = knownOverhead.threaderTime / knownOverhead.operations

  console.log('\nüîÑ CURRENT THROUGHPUT METRICS:')
  console.log(
    `üìà Operations per second: ${currentOpsPerSec.toFixed(0)} ops/sec`
  )
  console.log(
    `‚è±Ô∏è  Average latency: ${currentLatencyMs.toFixed(1)}ms per operation`
  )
  console.log(
    `üîß Setup overhead: ${(knownOverhead.setupTime / 100).toFixed(
      2
    )}ms per processor`
  )

  // Extrapolate to different scales
  console.log('\nüìä PROJECTED PERFORMANCE AT SCALE:')

  const scales = [
    {ops: 1, name: 'Single operation'},
    {ops: 10, name: 'Small batch'},
    {ops: 50, name: 'Medium batch'},
    {ops: 100, name: 'Large batch'},
    {ops: 500, name: 'Very large batch'},
    {ops: 1000, name: 'Massive batch'}
  ]

  scales.forEach(scale => {
    const estimatedTime = scale.ops * currentLatencyMs
    const estimatedOpsPerSec = (scale.ops / estimatedTime) * 1000
    const estimatedTotalTime = estimatedTime + scale.ops * 0.89 // Add setup overhead
    const actualOpsPerSec = (scale.ops / estimatedTotalTime) * 1000

    console.log(`\nüî∏ ${scale.name} (${scale.ops} ops):`)
    console.log(`   Execution time: ~${estimatedTime.toFixed(0)}ms`)
    console.log(`   With setup: ~${estimatedTotalTime.toFixed(0)}ms total`)
    console.log(`   Throughput: ~${actualOpsPerSec.toFixed(0)} ops/sec`)
    console.log(
      `   Time per op: ~${(estimatedTotalTime / scale.ops).toFixed(1)}ms`
    )
  })

  // Compare with native performance
  console.log('\n‚ö° NATIVE VS THREADER COMPARISON:')

  const nativeOpsPerSec = 10000000 // 10M ops/sec for simple arithmetic
  const efficiencyRatio = (currentOpsPerSec / nativeOpsPerSec) * 100

  console.log(
    `Native performance: ~${(nativeOpsPerSec / 1000000).toFixed(0)}M ops/sec`
  )
  console.log(`Threader performance: ~${currentOpsPerSec.toFixed(0)} ops/sec`)
  console.log(`Efficiency ratio: ${efficiencyRatio.toFixed(4)}%`)
  console.log(
    `Overhead factor: ${(nativeOpsPerSec / currentOpsPerSec).toFixed(
      0
    )}x slower`
  )

  // Calculate break-even points
  console.log('\nüéØ BREAK-EVEN ANALYSIS:')

  const coordinationCost = currentLatencyMs // ms per operation

  console.log(
    `Coordination cost: ~${coordinationCost.toFixed(1)}ms per operation`
  )
  console.log(
    `Break-even point: Operations taking >${coordinationCost.toFixed(0)}ms each`
  )
  console.log(
    `Recommended minimum: Operations taking >${(coordinationCost * 2).toFixed(
      0
    )}ms each`
  )

  // Real-world scenarios
  console.log('\nüåç REAL-WORLD SCENARIO ANALYSIS:')

  const scenarios = [
    {
      name: 'Simple math (x * 2)',
      nativeTime: 0.000001,
      recommendation: '‚ùå Never use'
    },
    {
      name: 'String operations',
      nativeTime: 0.001,
      recommendation: '‚ùå Never use'
    },
    {
      name: 'Small array sum (100 items)',
      nativeTime: 0.01,
      recommendation: '‚ùå Too much overhead'
    },
    {
      name: 'Medium computation (1ms)',
      nativeTime: 1,
      recommendation: '‚ùå Still too much overhead'
    },
    {
      name: 'Heavy computation (10ms)',
      nativeTime: 10,
      recommendation: '‚ö†Ô∏è Marginal benefit'
    },
    {
      name: 'Very heavy computation (100ms)',
      nativeTime: 100,
      recommendation: '‚úÖ Good candidate'
    },
    {
      name: 'Extremely heavy (1000ms)',
      nativeTime: 1000,
      recommendation: '‚úÖ Excellent candidate'
    }
  ]

  scenarios.forEach(scenario => {
    const threaderTime = scenario.nativeTime + coordinationCost
    const speedup = scenario.nativeTime / threaderTime
    const efficiency = (speedup - 1) * 100

    console.log(`\nüî∏ ${scenario.name}:`)
    console.log(`   Native time: ${scenario.nativeTime}ms`)
    console.log(`   Threader time: ~${threaderTime.toFixed(1)}ms`)
    console.log(
      `   Efficiency: ${efficiency > 0 ? '+' : ''}${efficiency.toFixed(0)}%`
    )
    console.log(`   ${scenario.recommendation}`)
  })

  // Theoretical maximum performance
  console.log('\nüöÄ THEORETICAL MAXIMUM PERFORMANCE:')

  // If we could eliminate setup overhead and reduce coordination cost
  const optimizedLatency = 1 // ms per operation (theoretical best case)
  const optimizedOpsPerSec = 1000 / optimizedLatency
  const improvementFactor = optimizedOpsPerSec / currentOpsPerSec

  console.log(`Current: ${currentOpsPerSec.toFixed(0)} ops/sec`)
  console.log(`Theoretical optimized: ${optimizedOpsPerSec.toFixed(0)} ops/sec`)
  console.log(`Potential improvement: ${improvementFactor.toFixed(1)}x faster`)
  console.log(
    `Still ${(nativeOpsPerSec / optimizedOpsPerSec).toFixed(
      0
    )}x slower than native`
  )

  // Usage recommendations based on throughput
  console.log('\nüí° USAGE RECOMMENDATIONS BASED ON THROUGHPUT:')

  if (currentOpsPerSec >= 1000) {
    console.log('üî• HIGH THROUGHPUT SYSTEM')
    console.log('   ‚Ä¢ Can handle 1000+ operations per second')
    console.log('   ‚Ä¢ Good for real-time processing pipelines')
    console.log('   ‚Ä¢ Suitable for moderate-scale parallel processing')
  } else if (currentOpsPerSec >= 100) {
    console.log('‚ö° MODERATE THROUGHPUT SYSTEM')
    console.log('   ‚Ä¢ Can handle 100+ operations per second')
    console.log('   ‚Ä¢ Good for batch processing')
    console.log('   ‚Ä¢ Best for heavy computational tasks')
  } else {
    console.log('üêå LOW THROUGHPUT SYSTEM')
    console.log('   ‚Ä¢ <100 operations per second')
    console.log('   ‚Ä¢ Only use for very heavy computations')
    console.log('   ‚Ä¢ Each task should take >100ms to justify overhead')
  }

  console.log('\nüéØ OPTIMAL USAGE PATTERNS:')
  console.log(`‚úÖ Batch size: 10-50 operations for best efficiency`)
  console.log(
    `‚úÖ Task duration: >${coordinationCost.toFixed(0)}ms per task minimum`
  )
  console.log(`‚úÖ Total workload: >1 second of computation`)
  console.log(`‚úÖ Use case: CPU-intensive, parallel-friendly algorithms`)

  console.log('\n‚ùå AVOID PATTERNS:')
  console.log(`‚ùå Task duration: <${coordinationCost.toFixed(0)}ms per task`)
  console.log(`‚ùå Total workload: <100ms of computation`)
  console.log(`‚ùå Use case: I/O operations, simple arithmetic`)
  console.log(`‚ùå Batch size: >1000 operations (diminishing returns)`)
}

async function quickThroughputTest(): Promise<void> {
  console.log('\nüß™ QUICK THROUGHPUT VERIFICATION')
  console.log('Testing actual throughput with working operations...')

  try {
    // Test that we know works (from earlier successful tests)
    const testOperations = 5 // Small number to avoid timeout issues

    console.log(`\nTesting ${testOperations} simple operations...`)
    const startTime = performance.now()

    const processors = Array.from({length: testOperations}, () =>
      threader(
        function (x: number) {
          return x * 2
        },
        42,
        {timeout: 5000}
      )
    )

    const results = await thread.all(...processors)
    const endTime = performance.now()

    const totalTime = endTime - startTime
    const actualOpsPerSec = (testOperations / totalTime) * 1000
    const actualLatency = totalTime / testOperations

    console.log(
      `‚úÖ Completed ${testOperations} operations in ${totalTime.toFixed(1)}ms`
    )
    console.log(`üìä Actual throughput: ${actualOpsPerSec.toFixed(0)} ops/sec`)
    console.log(
      `‚è±Ô∏è  Actual latency: ${actualLatency.toFixed(1)}ms per operation`
    )
    console.log(`‚úÖ Results correct: ${results[0] === 84}`)

    // Compare with our calculations
    const expectedOpsPerSec = (10 / 87.9) * 1000 // From earlier benchmark
    const accuracy = (actualOpsPerSec / expectedOpsPerSec) * 100

    console.log(`\nüìä Accuracy Check:`)
    console.log(`Expected: ${expectedOpsPerSec.toFixed(0)} ops/sec`)
    console.log(`Actual: ${actualOpsPerSec.toFixed(0)} ops/sec`)
    console.log(`Accuracy: ${accuracy.toFixed(0)}%`)
  } catch (error) {
    console.log(`‚ùå Throughput test failed: ${error.message}`)
    console.log(`üí° Using calculated estimates based on previous measurements`)
  }
}

async function main(): Promise<void> {
  try {
    await calculateLoopsPerSecond()
    await quickThroughputTest()

    console.log('\nüéâ LOOPS PER SECOND ANALYSIS COMPLETE!')
    console.log(
      '\nKey takeaway: Threader achieves ~100 ops/sec for simple operations,'
    )
    console.log(
      'making it suitable for heavy computational tasks (>10ms each).'
    )
  } catch (error) {
    console.error('‚ùå Analysis failed:', error.message)
  } finally {
    await thread.shutdown()
    console.log('\n‚úÖ Loops analysis complete!')
  }
}

main().catch(console.error)
